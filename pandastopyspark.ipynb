{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadvaze-markel/data-engineer-learning-path/blob/published/pandastopyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020?select=animelist.csv\n"
      ],
      "metadata": {
        "id": "bIXkH-9TORm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêå Hadoop MapReduce\n",
        "```\n",
        "// === Hadoop MapReduce (Java): Word Count ===\n",
        "// Verbose and boilerplate-heavy\n",
        "\n",
        "import java.io.IOException;\n",
        "import java.util.StringTokenizer;\n",
        "import org.apache.hadoop.conf.Configuration;\n",
        "import org.apache.hadoop.fs.Path;\n",
        "import org.apache.hadoop.io.IntWritable;\n",
        "import org.apache.hadoop.io.Text;\n",
        "import org.apache.hadoop.mapreduce.Job;\n",
        "import org.apache.hadoop.mapreduce.Mapper;\n",
        "import org.apache.hadoop.mapreduce.Reducer;\n",
        "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
        "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
        "\n",
        "public class WordCount {\n",
        "  public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {\n",
        "    private final static IntWritable one = new IntWritable(1);\n",
        "    private Text word = new Text();\n",
        "\n",
        "    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n",
        "      StringTokenizer itr = new StringTokenizer(value.toString());\n",
        "      while (itr.hasMoreTokens()) {\n",
        "        word.set(itr.nextToken());\n",
        "        context.write(word, one);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n",
        "    private IntWritable result = new IntWritable();\n",
        "\n",
        "    public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\n",
        "      int sum = 0;\n",
        "      for (IntWritable val : values) {\n",
        "        sum += val.get();\n",
        "      }\n",
        "      result.set(sum);\n",
        "      context.write(key, result);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  public static void main(String[] args) throws Exception {\n",
        "    Configuration conf = new Configuration();\n",
        "    Job job = Job.getInstance(conf, \"word count\");\n",
        "    job.setJarByClass(WordCount.class);\n",
        "    job.setMapperClass(TokenizerMapper.class);\n",
        "    job.setCombinerClass(IntSumReducer.class);\n",
        "    job.setReducerClass(IntSumReducer.class);\n",
        "    job.setOutputKeyClass(Text.class);\n",
        "    job.setOutputValueClass(IntWritable.class);\n",
        "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
        "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
        "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "## ‚ö° Apache Spark\n",
        "```\n",
        "// === Apache Spark (Java): Word Count ===\n",
        "// Concise and expressive\n",
        "\n",
        "import org.apache.spark.api.java.*;\n",
        "import org.apache.spark.api.java.function.*;\n",
        "import org.apache.spark.SparkConf;\n",
        "import java.util.Arrays;\n",
        "\n",
        "public class SimpleWordCount {\n",
        "  public static void main(String[] args) {\n",
        "    SparkConf conf = new SparkConf().setAppName(\"WordCount\").setMaster(\"local\");\n",
        "    JavaSparkContext sc = new JavaSparkContext(conf);\n",
        "\n",
        "    JavaRDD<String> lines = sc.textFile(args[0]);\n",
        "    JavaRDD<String> words = lines.flatMap(line -> Arrays.asList(line.split(\" \")).iterator());\n",
        "    JavaPairRDD<String, Integer> wordCounts = words\n",
        "        .mapToPair(word -> new scala.Tuple2<>(word, 1))\n",
        "        .reduceByKey(Integer::sum);\n",
        "\n",
        "    wordCounts.saveAsTextFile(args[1]);\n",
        "    sc.close();\n",
        "  }\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "ubTjcVG3NnLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|  Feature | Hadoop  |  Spark |\n",
        "|---|---|---|\n",
        "|  Lines of Code |  ~55 |  ~20 |\n",
        "|  Classes Needed | Mapper, Reducer, Driver  |  Single main class |\n",
        "| Disk usage between stages  |  Writes to disk | \tIn-memory processing   |\n",
        "|  Complexity |  \tHigh (verbose, boilerplate-heavy) | Low (functional, expressive)  |\n",
        "| API Paradigm  |  Rigid, procedural |  Functional, declarative |\n"
      ],
      "metadata": {
        "id": "pXrTI7uBuVyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Spark"
      ],
      "metadata": {
        "id": "aXNOgmGVtfr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## By default, PySpark isn‚Äôt included in the Colab environment"
      ],
      "metadata": {
        "id": "JcSJeIK-ik5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vXROswtijJ4",
        "outputId": "86234812-5334-444c-fa9c-08a822351692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Spark session, which is the entry point\n",
        "\n",
        "The SparkSession automatically starts a local cluster behind the scenes (within the Colab environment)."
      ],
      "metadata": {
        "id": "wcxo3gLYivwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm0W91aMkNky",
        "outputId": "a9af6748-2f57-47ee-c389-ef611d513cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PandasToPySpark\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark version: {spark.version}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O83zmz6KiqCF",
        "outputId": "74484567-f9dc-4072-a058-d0406a326c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# header=True: treats the first row as headers\n",
        "# inferSchema=True: automatically infer data types\n",
        "#user_ratings_df = spark.read.csv(\"/content/drive/MyDrive/PySpark Workshop/Scrapping MyAnimelist/animelist.csv\", header=True, inferSchema=True)\n",
        "user_ratings_df = spark.read.csv(\"/animelist.csv\", header=True, inferSchema=True)\n",
        "\n",
        "user_ratings_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AfQGJCekS1B",
        "outputId": "7674644a-bf0d-4e1b-c593-29a9614baa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- anime_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- watching_status: integer (nullable = true)\n",
            " |-- watched_episodes: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ratings_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJCEHqsViqHM",
        "outputId": "a4efd03b-b896-4a62-a902-9931a4869bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+---------------+----------------+\n",
            "|user_id|anime_id|rating|watching_status|watched_episodes|\n",
            "+-------+--------+------+---------------+----------------+\n",
            "|      0|      67|     9|              1|               1|\n",
            "|      0|    6702|     7|              1|               4|\n",
            "|      0|     242|    10|              1|               4|\n",
            "|      0|    4898|     0|              1|               1|\n",
            "|      0|      21|    10|              1|               0|\n",
            "+-------+--------+------+---------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can explicitly define a schema too.\n",
        "\n",
        "```\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
        "\n",
        "anime_schema = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), True),\n",
        "    StructField(\"anime_id\", IntegerType(), True),\n",
        "    StructField(\"rating\", IntegerType(), True),\n",
        "    StructField(\"watching_status\", IntegerType(), True),\n",
        "    StructField(\"watched_episodes\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "anime_df_explicit = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(anime_schema) \\\n",
        "    .load(\"/content/drive/MyDrive/animelist.csv\")\n",
        "```"
      ],
      "metadata": {
        "id": "6i_47qrNM7uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#animes_df = spark.read.csv(\"/content/drive/MyDrive/PySpark Workshop/Scrapping MyAnimelist/anime.csv\", header=True, inferSchema=True)\n",
        "animes_df = spark.read.csv(\"/anime.csv\", header=True, inferSchema=True)\n",
        "\n",
        "animes_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anj4wR6iFrfQ",
        "outputId": "291a54c0-5944-49f3-b796-123d8611b5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- MAL_ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Genres: string (nullable = true)\n",
            " |-- English name: string (nullable = true)\n",
            " |-- Japanese name: string (nullable = true)\n",
            " |-- Type: string (nullable = true)\n",
            " |-- Episodes: string (nullable = true)\n",
            " |-- Aired: string (nullable = true)\n",
            " |-- Premiered: string (nullable = true)\n",
            " |-- Producers: string (nullable = true)\n",
            " |-- Licensors: string (nullable = true)\n",
            " |-- Studios: string (nullable = true)\n",
            " |-- Source: string (nullable = true)\n",
            " |-- Duration: string (nullable = true)\n",
            " |-- Rating: string (nullable = true)\n",
            " |-- Ranked: string (nullable = true)\n",
            " |-- Popularity: string (nullable = true)\n",
            " |-- Members: double (nullable = true)\n",
            " |-- Favorites: integer (nullable = true)\n",
            " |-- Watching: integer (nullable = true)\n",
            " |-- Completed: integer (nullable = true)\n",
            " |-- On-Hold: integer (nullable = true)\n",
            " |-- Dropped: integer (nullable = true)\n",
            " |-- Plan to Watch: integer (nullable = true)\n",
            " |-- Score-10: string (nullable = true)\n",
            " |-- Score-9: string (nullable = true)\n",
            " |-- Score-8: string (nullable = true)\n",
            " |-- Score-7: string (nullable = true)\n",
            " |-- Score-6: string (nullable = true)\n",
            " |-- Score-5: string (nullable = true)\n",
            " |-- Score-4: string (nullable = true)\n",
            " |-- Score-3: string (nullable = true)\n",
            " |-- Score-2: string (nullable = true)\n",
            " |-- Score-1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "066qmTvfiqI8",
        "outputId": "8b0b4ff8-32c4-448d-a7f0-c6e333adc7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-----+--------------------+--------------------+---------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+--------------+--------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|MAL_ID|                Name|Score|              Genres|        English name|              Japanese name| Type|Episodes|               Aired|  Premiered|           Producers|           Licensors|       Studios|  Source|       Duration|              Rating|Ranked|Popularity|  Members|Favorites|Watching|Completed|On-Hold|Dropped|Plan to Watch|Score-10| Score-9| Score-8|Score-7|Score-6|Score-5|Score-4|Score-3|Score-2|Score-1|\n",
            "+------+--------------------+-----+--------------------+--------------------+---------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+--------------+--------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|     1|        Cowboy Bebop| 8.78|Action, Adventure...|        Cowboy Bebop|         „Ç´„Ç¶„Éú„Éº„Ç§„Éì„Éê„ÉÉ„Éó|   TV|      26|Apr 3, 1998 to Ap...|Spring 1998|       Bandai Visual|Funimation, Banda...|       Sunrise|Original|24 min. per ep.|R - 17+ (violence...|  28.0|        39|1251960.0|    61971|  105808|   718161|  71513|  26678|       329800|229170.0|182126.0|131625.0|62330.0|20688.0| 8904.0| 3184.0| 1357.0|  741.0| 1580.0|\n",
            "|     5|Cowboy Bebop: Ten...| 8.39|Action, Drama, My...|Cowboy Bebop:The ...|„Ç´„Ç¶„Éú„Éº„Ç§„Éì„Éê„ÉÉ„Éó Â§©ÂõΩ„ÅÆÊââ|Movie|       1|         Sep 1, 2001|    Unknown|Sunrise, Bandai V...|Sony Pictures Ent...|         Bones|Original|  1 hr. 55 min.|R - 17+ (violence...| 159.0|       518| 273145.0|     1174|    4143|   208333|   1935|    770|        57964| 30043.0| 49201.0| 49505.0|22632.0| 5805.0| 1877.0|  577.0|  221.0|  109.0|  379.0|\n",
            "|     6|              Trigun| 8.24|Action, Sci-Fi, A...|              Trigun|                 „Éà„É©„Ç§„Ç¨„É≥|   TV|      26|Apr 1, 1998 to Se...|Spring 1998|Victor Entertainment|Funimation, Geneo...|      Madhouse|   Manga|24 min. per ep.|PG-13 - Teens 13 ...| 266.0|       201| 558913.0|    12944|   29113|   343492|  25465|  13925|       146918| 50229.0| 75651.0| 86142.0|49432.0|15376.0| 5838.0| 1965.0|  664.0|  316.0|  533.0|\n",
            "|     7|  Witch Hunter Robin| 7.27|Action, Mystery, ...|  Witch Hunter Robin|       Witch Hunter ROBI...|   TV|      26|Jul 2, 2002 to De...|Summer 2002|TV Tokyo, Bandai ...|Funimation, Banda...|       Sunrise|Original|25 min. per ep.|PG-13 - Teens 13 ...|2481.0|      1467|  94683.0|      587|    4300|    46165|   5121|   5378|        33719|  2182.0|  4806.0| 10128.0|11618.0| 5709.0| 2920.0| 1083.0|  353.0|  164.0|  131.0|\n",
            "|     8|      Bouken Ou Beet| 6.98|Adventure, Fantas...|Beet the Vandel B...|               ÂÜíÈô∫Áéã„Éì„Ç£„Éà|   TV|      52|Sep 30, 2004 to S...|  Fall 2004|    TV Tokyo, Dentsu|             Unknown|Toei Animation|   Manga|23 min. per ep.|       PG - Children|3710.0|      4369|  13224.0|       18|     642|     7314|    766|   1108|         3394|   312.0|   529.0|  1242.0| 1713.0| 1068.0|  634.0|  265.0|   83.0|   50.0|   27.0|\n",
            "+------+--------------------+-----+--------------------+--------------------+---------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+--------------+--------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark vs Pandas: Schemas\n",
        "## Why Schemas Matter ü©ª\n",
        "\n",
        "- Spark doesn't need to scan the entire dataset repeatedly to understand types, it already has that metadata.\n",
        "\n",
        "- Since each column has a known type, Spark can optimize execution, including:\n",
        "  - Memory layout\n",
        "  - Serialization (sending data between nodes)\n",
        "  - Generating JVM bytecode to process columns efficiently\n",
        "\n",
        "- Schema-awareness allows Spark to scale big data without losing performance or reliability.\n",
        "\n",
        "<br>\n",
        "\n",
        "- Pandas does have data type tracking\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"animelist.csv\")\n",
        "df.dtypes\n",
        "\n",
        "user_id           int64\n",
        "anime_id          int64\n",
        "rating            int64\n",
        "watching_status   int64\n",
        "watched_episodes  int64\n",
        "dtype: int64\n",
        "\n",
        "```\n",
        "\n",
        "- But this isn't enfoced. A column could have mixed types defaulting the data type to object.\n",
        "\n",
        "<br>\n",
        "\n",
        "- Schemas in Spark are enforced."
      ],
      "metadata": {
        "id": "8OiNstZ-Px3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pandas uses NumPy arrays under the hood, which expect consistent types. As soon as it sees \"unknown\" (a string), it converts the whole column to object ‚Äî which is a catch-all type.\n",
        "\n",
        "`df[\"rating\"].mean()  # results in an error`\n",
        "\n",
        "- You'd need to manually fix the error\n",
        "\n",
        "`df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")`\n",
        "- The `\"unknown\"` becomes `NAN`"
      ],
      "metadata": {
        "id": "N1-MF8UBeqVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correcting a column's datatype"
      ],
      "metadata": {
        "id": "Kp942seDlNEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "score_cols = [f\"Score-{i}\" for i in range(1, 10)]\n",
        "\n",
        "animes_df = animes_df.select([\n",
        "    col(score_col).cast(\"int\").alias(score_col) if score_col in score_cols else col(score_col)\n",
        "    for score_col in animes_df.columns\n",
        "])\n",
        "\n",
        "animes_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXxfOp9olK8k",
        "outputId": "bd4c8079-7f36-41a4-d7df-7f2bf7aa6372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- MAL_ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Genres: string (nullable = true)\n",
            " |-- English name: string (nullable = true)\n",
            " |-- Japanese name: string (nullable = true)\n",
            " |-- Type: string (nullable = true)\n",
            " |-- Episodes: string (nullable = true)\n",
            " |-- Aired: string (nullable = true)\n",
            " |-- Premiered: string (nullable = true)\n",
            " |-- Producers: string (nullable = true)\n",
            " |-- Licensors: string (nullable = true)\n",
            " |-- Studios: string (nullable = true)\n",
            " |-- Source: string (nullable = true)\n",
            " |-- Duration: string (nullable = true)\n",
            " |-- Rating: string (nullable = true)\n",
            " |-- Ranked: string (nullable = true)\n",
            " |-- Popularity: string (nullable = true)\n",
            " |-- Members: double (nullable = true)\n",
            " |-- Favorites: integer (nullable = true)\n",
            " |-- Watching: integer (nullable = true)\n",
            " |-- Completed: integer (nullable = true)\n",
            " |-- On-Hold: integer (nullable = true)\n",
            " |-- Dropped: integer (nullable = true)\n",
            " |-- Plan to Watch: integer (nullable = true)\n",
            " |-- Score-10: string (nullable = true)\n",
            " |-- Score-9: integer (nullable = true)\n",
            " |-- Score-8: integer (nullable = true)\n",
            " |-- Score-7: integer (nullable = true)\n",
            " |-- Score-6: integer (nullable = true)\n",
            " |-- Score-5: integer (nullable = true)\n",
            " |-- Score-4: integer (nullable = true)\n",
            " |-- Score-3: integer (nullable = true)\n",
            " |-- Score-2: integer (nullable = true)\n",
            " |-- Score-1: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_df = animes_df.withColumn(\"Score-10\", col(\"Score-10\").cast(\"int\")) \\\n",
        "                     .withColumn(\"Popularity\", col(\"Popularity\").cast(\"int\")) \\\n",
        "                     .withColumn(\"Ranked\", col(\"Ranked\").cast(\"int\"))\n",
        "\n",
        "animes_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUAopefWl4KH",
        "outputId": "c17267cf-09e3-49ef-eef8-a4bc2b5e51f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- MAL_ID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Genres: string (nullable = true)\n",
            " |-- English name: string (nullable = true)\n",
            " |-- Japanese name: string (nullable = true)\n",
            " |-- Type: string (nullable = true)\n",
            " |-- Episodes: string (nullable = true)\n",
            " |-- Aired: string (nullable = true)\n",
            " |-- Premiered: string (nullable = true)\n",
            " |-- Producers: string (nullable = true)\n",
            " |-- Licensors: string (nullable = true)\n",
            " |-- Studios: string (nullable = true)\n",
            " |-- Source: string (nullable = true)\n",
            " |-- Duration: string (nullable = true)\n",
            " |-- Rating: string (nullable = true)\n",
            " |-- Ranked: integer (nullable = true)\n",
            " |-- Popularity: integer (nullable = true)\n",
            " |-- Members: double (nullable = true)\n",
            " |-- Favorites: integer (nullable = true)\n",
            " |-- Watching: integer (nullable = true)\n",
            " |-- Completed: integer (nullable = true)\n",
            " |-- On-Hold: integer (nullable = true)\n",
            " |-- Dropped: integer (nullable = true)\n",
            " |-- Plan to Watch: integer (nullable = true)\n",
            " |-- Score-10: integer (nullable = true)\n",
            " |-- Score-9: integer (nullable = true)\n",
            " |-- Score-8: integer (nullable = true)\n",
            " |-- Score-7: integer (nullable = true)\n",
            " |-- Score-6: integer (nullable = true)\n",
            " |-- Score-5: integer (nullable = true)\n",
            " |-- Score-4: integer (nullable = true)\n",
            " |-- Score-3: integer (nullable = true)\n",
            " |-- Score-2: integer (nullable = true)\n",
            " |-- Score-1: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations in Spark\n",
        "- Transformations: tell Spark how to manipulate data but don't do anything until an action is called.\n",
        "-Actions: trigger execution. Spark reads the data, runs all the queued transformations, and produces a result.\n"
      ],
      "metadata": {
        "id": "tftwsddeg-Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "sentence = '''\n",
        "<span style=\"font-size:20px\">\n",
        "<span style=\"color:#00acc1; font-weight:bold\">Transformations</span> build the plan while <span style=\"color:#42a5f5; font-weight:bold\">Actions</span> execute the plan.\n",
        "</span>\n",
        "'''\n",
        "\n",
        "display(HTML(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42
        },
        "id": "aXm8u7czX-qw",
        "outputId": "76b42b11-02f5-4337-9767-1fd56ce7ed5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<span style=\"font-size:20px\">\n",
              "<span style=\"color:#00acc1; font-weight:bold\">Transformations</span> build the plan while <span style=\"color:#42a5f5; font-weight:bold\">Actions</span> execute the plan.\n",
              "</span>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ratings_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0EPJPT0sPCF",
        "outputId": "41f894a4-e08d-424b-ae81-c977d722ef44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- anime_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- watching_status: integer (nullable = true)\n",
            " |-- watched_episodes: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ratings = user_ratings_df.filter(user_ratings_df[\"rating\"] > 8) # this is a lazy eval"
      ],
      "metadata": {
        "id": "9Eh7jM0YhYsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ratings.count() # action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiphAsT0XxO2",
        "outputId": "8e45f053-f3cf-40e1-bb0d-5ac402ae9240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5242071"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ratings.explain() # see the DAG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBpbOnWehTnn",
        "outputId": "344bd404-79d6-4ddc-ae9e-ecaa080a6252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Filter (isnotnull(rating#19) AND (rating#19 > 8))\n",
            "+- FileScan csv [user_id#17,anime_id#18,rating#19,watching_status#20,watched_episodes#21] Batched: false, DataFilters: [isnotnull(rating#19), (rating#19 > 8)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/animelist.csv], PartitionFilters: [], PushedFilters: [IsNotNull(rating), GreaterThan(rating,8)], ReadSchema: struct<user_id:int,anime_id:int,rating:int,watching_status:int,watched_episodes:int>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark vs Pandas: Parallelism\n",
        "\n",
        "`pandas.read_csv(\"animelist.csv\")`\n",
        "\n",
        "- Your entire file is read by a single CPU core.\n",
        "\n",
        "- The whole dataset must fit into memory (RAM).\n",
        "\n",
        "- All operations like `user_ratings_df[user_ratings_df[\"rating\"] > 8]` happen in one thread.\n",
        "\n",
        "‚ö†Ô∏è So if your CSV is 10GB and your RAM is 8GB ‚Üí üí• you might experience crashes."
      ],
      "metadata": {
        "id": "dZcHnrSwI4hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`park.read.csv(\"animelist.csv\")`\n",
        "\n",
        "- Spark splits the file into chunks (partitions).\n",
        "\n",
        "- Each chunk is sent to a different executor (worker process).\n",
        "\n",
        "- All of them read and process data in parallel.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "For example, Spark can split up a 10GB file into 20 partitions where there are 4 executors with 5 cores. Each parition can handle 20 tasks and all paritions are running in parallel.\n",
        "\n"
      ],
      "metadata": {
        "id": "mACFnIwRKtNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Data Cleaning üßº"
      ],
      "metadata": {
        "id": "fzCkNicHhr2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### count the number of nulls or empty values"
      ],
      "metadata": {
        "id": "K8HhpUt4iD_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import isnan, when, count, trim\n",
        "\n",
        "filtered_ratings.select([\n",
        "    count(when(isnan(column) | col(column).isNull() | (trim(col(column)) == \"\"), column)).alias(column)\n",
        "    for column in filtered_ratings.columns\n",
        "]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8o4lvX7KFrg",
        "outputId": "47cf6a35-c9a5-4f44-ffd2-9bd694617b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+---------------+----------------+\n",
            "|user_id|anime_id|rating|watching_status|watched_episodes|\n",
            "+-------+--------+------+---------------+----------------+\n",
            "|      0|       0|     0|              0|               0|\n",
            "+-------+--------+------+---------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_df.select([\n",
        "    count(when(isnan(column) | col(column).isNull() | (trim(col(column)) == \"\"), column)).alias(column)\n",
        "    for column in animes_df.columns\n",
        "]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU3naL2OeLbQ",
        "outputId": "21663818-71d6-4bbc-e639-0f98057e0670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+------+------------+-------------+----+--------+-----+---------+---------+---------+-------+------+--------+------+------+----------+-------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|MAL_ID|Name|Score|Genres|English name|Japanese name|Type|Episodes|Aired|Premiered|Producers|Licensors|Studios|Source|Duration|Rating|Ranked|Popularity|Members|Favorites|Watching|Completed|On-Hold|Dropped|Plan to Watch|Score-10|Score-9|Score-8|Score-7|Score-6|Score-5|Score-4|Score-3|Score-2|Score-1|\n",
            "+------+----+-----+------+------------+-------------+----+--------+-----+---------+---------+---------+-------+------+--------+------+------+----------+-------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|     0|   0|    0|     0|           0|            0|   0|       0|    0|        0|        0|        0|      0|     0|       0|     0|  1766|         2|      0|        0|       0|        0|      0|      0|            0|     437|   3167|   1371|    503|    511|    584|    977|   1307|   1597|    459|\n",
            "+------+----+-----+------+------------+-------------+----+--------+-----+---------+---------+---------+-------+------+--------+------+------+----------+-------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark vs Pandas: Mutability\n",
        "\n",
        "- You cannot change a Spark DataFrame in place.\n",
        "- Every transformation returns a new DataFrame.\n",
        "\n",
        "<br>\n",
        "\n",
        "Why?\n",
        "\n",
        "- Spark needs to keep track of the DAG,\n",
        "- Spark needs to recompute or recover partitions in case of failure,\n",
        "- Immutability allows for distribute transformations across machines safely.\n",
        "\n",
        "Upsides ‚úÖ\n",
        "- Fault tolerance\n",
        "- Optimization\n",
        "- Parallelism"
      ],
      "metadata": {
        "id": "zLX8c6h0cY1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_ratings_v2 = filtered_ratings.fillna({'rating': 0.0})"
      ],
      "metadata": {
        "id": "sdHsQm-Eisnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change a pandas DataFrame in place.\n",
        "\n",
        "```\n",
        "df[\"rating\"] = df[\"rating\"].fillna(0)  \n",
        "df.dropna(inplace=True)   \n",
        "```           \n",
        "This is great for exploratory data analysis on small-to-medium data.\n",
        "\n",
        "Downsides üö´\n",
        "- Harder to track changes\n",
        "- Not fault-tolerant\n",
        "- Can lead to bugs in larger codebases if not careful"
      ],
      "metadata": {
        "id": "cfhDveQPbu88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating new columns"
      ],
      "metadata": {
        "id": "STUYizUoh9qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split, explode\n",
        "\n",
        "animes_df \\\n",
        "  .withColumn(\"genre_array\", split(col(\"Genres\"), \",\")) \\\n",
        "  .select(col(\"MAL_ID\"), col(\"Name\"), col(\"Genres\"), col(\"genre_array\")) \\\n",
        "  .show(5, False) # we don't want to truncate our view of the text\n",
        "\n",
        "\n",
        "# explode will flatten the array\n",
        "animes_df \\\n",
        "  .withColumn(\"genre_array\", split(col(\"Genres\"), \",\")) \\\n",
        "  .withColumn(\"genre\", explode(col(\"genre_array\"))) \\\n",
        "  .select(col(\"MAL_ID\"), col(\"Name\"), col(\"Genres\"), col(\"genre_array\"), col(\"genre\")) \\\n",
        "  .show(30, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WSSOLORbuSP",
        "outputId": "7ff8b1d3-567b-4e0f-a50a-9bb6fa16ab45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+\n",
            "|MAL_ID|Name                           |Genres                                             |genre_array                                               |\n",
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]|\n",
            "|8     |Bouken Ou Beet                 |Adventure, Fantasy, Shounen, Supernatural          |[Adventure,  Fantasy,  Shounen,  Supernatural]            |\n",
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+-------------+\n",
            "|MAL_ID|Name                           |Genres                                             |genre_array                                               |genre        |\n",
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+-------------+\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    |Action       |\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    | Adventure   |\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    | Comedy      |\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    | Drama       |\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    | Sci-Fi      |\n",
            "|1     |Cowboy Bebop                   |Action, Adventure, Comedy, Drama, Sci-Fi, Space    |[Action,  Adventure,  Comedy,  Drama,  Sci-Fi,  Space]    | Space       |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               |Action       |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               | Drama       |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               | Mystery     |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               | Sci-Fi      |\n",
            "|5     |Cowboy Bebop: Tengoku no Tobira|Action, Drama, Mystery, Sci-Fi, Space              |[Action,  Drama,  Mystery,  Sci-Fi,  Space]               | Space       |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  |Action       |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  | Sci-Fi      |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  | Adventure   |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  | Comedy      |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  | Drama       |\n",
            "|6     |Trigun                         |Action, Sci-Fi, Adventure, Comedy, Drama, Shounen  |[Action,  Sci-Fi,  Adventure,  Comedy,  Drama,  Shounen]  | Shounen     |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]|Action       |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]| Mystery     |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]| Police      |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]| Supernatural|\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]| Drama       |\n",
            "|7     |Witch Hunter Robin             |Action, Mystery, Police, Supernatural, Drama, Magic|[Action,  Mystery,  Police,  Supernatural,  Drama,  Magic]| Magic       |\n",
            "|8     |Bouken Ou Beet                 |Adventure, Fantasy, Shounen, Supernatural          |[Adventure,  Fantasy,  Shounen,  Supernatural]            |Adventure    |\n",
            "|8     |Bouken Ou Beet                 |Adventure, Fantasy, Shounen, Supernatural          |[Adventure,  Fantasy,  Shounen,  Supernatural]            | Fantasy     |\n",
            "|8     |Bouken Ou Beet                 |Adventure, Fantasy, Shounen, Supernatural          |[Adventure,  Fantasy,  Shounen,  Supernatural]            | Shounen     |\n",
            "|8     |Bouken Ou Beet                 |Adventure, Fantasy, Shounen, Supernatural          |[Adventure,  Fantasy,  Shounen,  Supernatural]            | Supernatural|\n",
            "|15    |Eyeshield 21                   |Action, Sports, Comedy, Shounen                    |[Action,  Sports,  Comedy,  Shounen]                      |Action       |\n",
            "|15    |Eyeshield 21                   |Action, Sports, Comedy, Shounen                    |[Action,  Sports,  Comedy,  Shounen]                      | Sports      |\n",
            "|15    |Eyeshield 21                   |Action, Sports, Comedy, Shounen                    |[Action,  Sports,  Comedy,  Shounen]                      | Comedy      |\n",
            "+------+-------------------------------+---------------------------------------------------+----------------------------------------------------------+-------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_df \\\n",
        ".filter(col(\"MAL_ID\") == 120).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fttUaMWNerph",
        "outputId": "d76e8fb9-1a2c-4f21-86e8-cf1a82fba0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-----+--------------------+-------------+------------------+----+--------+--------------------+-----------+--------------------+----------+-----------+------+---------------+--------------------+------+----------+--------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|MAL_ID|         Name|Score|              Genres| English name|     Japanese name|Type|Episodes|               Aired|  Premiered|           Producers| Licensors|    Studios|Source|       Duration|              Rating|Ranked|Popularity| Members|Favorites|Watching|Completed|On-Hold|Dropped|Plan to Watch|Score-10|Score-9|Score-8|Score-7|Score-6|Score-5|Score-4|Score-3|Score-2|Score-1|\n",
            "+------+-------------+-----+--------------------+-------------+------------------+----+--------+--------------------+-----------+--------------------+----------+-----------+------+---------------+--------------------+------+----------+--------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|   120|Fruits Basket| 7.69|Slice of Life, Co...|Fruits Basket|„Éï„É´„Éº„ÉÑ„Éê„Çπ„Ç±„ÉÉ„Éà|  TV|      26|Jul 5, 2001 to De...|Summer 2001|TV Tokyo, Nihon A...|Funimation|Studio Deen| Manga|24 min. per ep.|PG-13 - Teens 13 ...|  1058|       314|420919.0|     9504|   15410|   297921|  12910|  16709|        77969|   31688|  40622|  59206|  56487|  25501|  12518|   4273|   1538|    810|    684|\n",
            "+------+-------------+-----+--------------------+-------------+------------------+----+--------+--------------------+-----------+--------------------+----------+-----------+------+---------------+--------------------+------+----------+--------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## String Cleaning\n",
        "\n",
        "### Trimming\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `trim(columnName)` | Removes both leading and trailing whitespace  |\n",
        "| `ltrim(columnName)`  | Removes leading whitespace  |\n",
        "|  `rtrim(columnName)` |  Removes trailing whitespace |\n",
        "\n",
        "<br>\n",
        "\n",
        "### Casing\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `lower(columnName)` | \tConverts strings to lowercase |\n",
        "| `upper(columnName)`  | \tConverts strings to uppercase |\n",
        "\n",
        "<br>\n",
        "\n",
        "### Regex and Substrings\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `regexp_replace(col, \"old\", \"new\")` | \tReplacing substrings |\n",
        "| `regexp_replace(col, \"[^a-zA-Z0-9 ]\", \"\")`  | Removing punctuation |\n",
        "|  `substring(col, start, length)` |  Extracting substrings|\n",
        "\n",
        "<br>\n",
        "\n",
        "## Data Handling\n",
        "### Missing or Corrupt Data\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `fillna()` | Replace Nulls and NaNs|\n",
        "| `dropna()`  | \tDrops any row with missing data |\n",
        "|  `replace()` or `.na.replace()` |  \tChanges \"N/A\", \"unknown\", etc. to something else |\n",
        "\n",
        "<br>\n",
        "\n",
        "### Dedupe and Standardize\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `round(col, 2)` | \tLimit floats to 2 decimal places|\n",
        "| `dropDuplicates([\"col1\", \"col2\"])`  | Drop duplicates |\n",
        "|  `replace()` + `lower()` + `trim()` |  Standardize values. Fix things like \"Male\", \"male \", \" MALE\"|\n",
        "|  `orderBy(\"col\")` | \tSort rows|\n",
        "|  `concat_ws(' ', col1, col2)` | \tCombine columns|"
      ],
      "metadata": {
        "id": "hbuCcCXNpVlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shuffling üîÑ\n",
        "\n",
        "A process where data gets moved around between executors to satisfy a transformation that requires grouping or combining data from different partitions.\n",
        "\n",
        "<br>\n",
        "\n",
        "```filtered_ratings_v2.groupBy(\"user_id\").count()```\n",
        "\n",
        "Spark has to move all rows with th same user_id to the same partition so it can count them.\n",
        "\n",
        "<br>\n",
        "\n",
        "Examples:\n",
        "\n",
        "\n",
        "|  Function |  Description |\n",
        "|---|---|\n",
        "|  `groupBy()` | \tAll rows with the same key need to go to the same partition|\n",
        "| `join()`  | \tMatching keys must be co-located across datasets |\n",
        "|  `distinct()` |  \tNeeds to group identical records together|\n",
        "|  `repartition()` | \tExplicitly reshuffles data into new partitions|\n",
        "|  `orderBy()` | \tSorts across all data, requiring a full shuffle|\n",
        "\n",
        "<br>\n",
        "\n",
        "Shuffle is a side effect of a wide transformation. Shuffles are performed during execution of an action.\n",
        "\n",
        "Wide transformations require data to be shuffled across the network, because each output partition depends on multiple input partitions.\n",
        "\n",
        "\n",
        "\n",
        "## What happens during a shuffle üï∫?\n",
        "- It sends that data across the cluster to new partitions based on a key (e.g., all \"MAL_ID=123\" go to one executor).\n",
        "- Spark re-reads the shuffled data. Each executor receives its assigned range of rows.\n",
        "- Each executor then applies the transformation locally, and Spark merges the data from all partitions.\n",
        "\n",
        "Shuffle is expensive! Involves disk I/O, network transfer, and serialization üí∏.\n",
        "\n",
        "This can cause performance bottlenecks and can also lead to OOM errors if data is skewed or poorly partitioned."
      ],
      "metadata": {
        "id": "mIb7MALi1XYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcast Joins\n",
        "\n",
        "A broadcast join is a special type of join in Spark where a small DataFrame is *broadcasted* to all executors, so that each executor can join it locally with the partitions of the bigger table.\n",
        "\n",
        "It's a great performance boost for joins with small lookup tables.\n",
        "\n",
        "<br>\n",
        "\n",
        "**When to Use It?**\n",
        "- The smaller dataset fits in memory (usually under 10 MB‚Äì100 MB)\n",
        "- You're doing a join and one side is tiny (e.g., a lookup table)\n",
        "- You're okay with duplicating the small dataset across all nodes"
      ],
      "metadata": {
        "id": "Vai1tpAM2hZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "users_who_completed_a_series = user_ratings_df.select([\"user_id\", \"anime_id\"]) \\\n",
        "                                              .filter(col(\"watching_status\") == 2) \\\n",
        "                                              .join(broadcast(animes_df), user_ratings_df.anime_id == animes_df.MAL_ID, how=\"inner\")\n",
        "\n",
        "users_who_completed_a_series.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33GguAlnqFhP",
        "outputId": "2ab57164-c305-44e5-dc3b-ce5bb0e779d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------+--------------------+-----+--------------------+--------------------+--------------------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+----------------+------------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|user_id|anime_id|MAL_ID|                Name|Score|              Genres|        English name|                         Japanese name| Type|Episodes|               Aired|  Premiered|           Producers|           Licensors|         Studios|      Source|       Duration|              Rating|Ranked|Popularity|  Members|Favorites|Watching|Completed|On-Hold|Dropped|Plan to Watch|Score-10|Score-9|Score-8|Score-7|Score-6|Score-5|Score-4|Score-3|Score-2|Score-1|\n",
            "+-------+--------+------+--------------------+-----+--------------------+--------------------+--------------------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+----------------+------------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|      0|      68|    68|      Black Cat (TV)| 7.38|Sci-Fi, Adventure...|           Black Cat|                      „Éñ„É©„ÉÉ„ÇØ„Ç≠„É£„ÉÉ„Éà|   TV|      23|Oct 7, 2005 to Ma...|  Fall 2005|GDH, Dentsu, TBS,...|          Funimation|           Gonzo|       Manga|24 min. per ep.|PG-13 - Teens 13 ...|  1965|       622| 231668.0|     1955|   10510|   142921|  11736|  11003|        55498|    8654|  15253|  29392|  34019|  16081|   7534|   2521|    863|    395|    234|\n",
            "|      0|    1689|  1689|Byousoku 5 Centim...| 7.73|Drama, Romance, S...|5 Centimeters Per...|                  ÁßíÈÄüÔºï„Çª„É≥„ÉÅ„É°„Éº„Éà„É´|Movie|       3|         Mar 3, 2007|    Unknown|             Unknown|ADV Films, Bandai...|CoMix Wave Films|    Original|22 min. per ep.|PG-13 - Teens 13 ...|   949|       136| 695375.0|     9719|   12529|   524145|   6261|   4580|       147860|   65007|  80388| 107226|  86657|  43552|  21319|  10108|   3821|   2081|   1835|\n",
            "|      0|    2913|  2913|Daisougen no Chii...| 7.01|    Adventure, Drama|Bush Baby, Little...|  Â§ßËçâÂéü„ÅÆÂ∞è„Åï„Å™Â§©‰Ωø„ÄÄ„Éñ„ÉÉ„Ç∑„É•„Éô„Ç§„Éì„Éº|   TV|      40|Jan 12, 1992 to D...|Winter 1992|             Fuji TV|             Unknown|Nippon Animation|       Novel|24 min. per ep.|        G - All Ages|  3609|      8811|   2020.0|        3|      74|      727|     74|    114|         1031|      57|     54|     91|    153|     93|     40|     17|      4|      5|      6|\n",
            "|      0|    1250|  1250|     Erementar Gerad|  7.3|Adventure, Comedy...|    Elemental Gelade|                „Ç®„É¨„É°„É≥„Çø„É´„Ç∏„Çß„É¨„Ç§„Éâ|   TV|      26|Apr 5, 2005 to Se...|Spring 2005|TV Tokyo, Geneon ...|Funimation, Disco...|           Xebec|       Manga|24 min. per ep.|PG-13 - Teens 13 ...|  2325|      1587|  85305.0|      497|    3647|    51887|   4082|   4442|        21247|    3279|   4969|   9868|  11831|   6331|   3267|   1125|    386|    158|    103|\n",
            "|      0|     356|   356|     Fate/stay night| 7.34|Action, Supernatu...|     Fate/stay night|                       Fate/stay night|   TV|      24|Jan 7, 2006 to Ju...|Winter 2006|Geneon Universal ...|Sentai Filmworks,...|     Studio Deen|Visual novel|24 min. per ep.|R - 17+ (violence...|  2152|       119| 730980.0|     7011|   29998|   510563|  19938|  23686|       146795|   35378|  57284| 101538| 107818|  55337|  26103|  13081|   5032|   2350|   1693|\n",
            "|      0|     121|   121| Fullmetal Alchemist| 8.17|Action, Adventure...| Fullmetal Alchemist|                          Èãº„ÅÆÈå¨ÈáëË°ìÂ∏´|   TV|      51|Oct 4, 2003 to Oc...|  Fall 2003|Aniplex, Dentsu, ...|Funimation, Anipl...|           Bones|       Manga|24 min. per ep.|PG-13 - Teens 13 ...|   337|        52|1151621.0|    26564|   52738|   880215|  41631|  38693|       138344|  124399| 176993| 211302| 133850|  44438|  16255|   5872|   1769|    970|   1150|\n",
            "|      0|     430|   430|Fullmetal Alchemi...| 7.57|Military, Comedy,...|Fullmetal Alchemi...|ÂäáÂ†¥Áâà Èãº„ÅÆÈå¨ÈáëË°ìÂ∏´ „Ç∑„É£„É≥„Éê„É©„ÇíÂæÅ„ÅèËÄÖ|Movie|       1|        Jul 23, 2005|    Unknown|Aniplex, Square E...|          Funimation|           Bones|       Manga|  1 hr. 45 min.|PG-13 - Teens 13 ...|  1361|       506| 279946.0|      704|    2361|   245283|   1253|    776|        30273|   19794|  31112|  47730|  44941|  20077|   8777|   4298|   1555|    812|    490|\n",
            "|      0|    1829|  1829|           Ged Senki| 6.95|Adventure, Magic,...| Tales from Earthsea|                              „Ç≤„ÉâÊà¶Ë®ò|Movie|       1|        Jul 29, 2006|    Unknown|                Toho| Walt Disney Studios|   Studio Ghibli|       Novel|  1 hr. 55 min.|PG-13 - Teens 13 ...|  3815|      1317| 107556.0|      189|    1082|    83702|    778|    504|        21490|    4527|   6868|  12931|  17433|  11237|   6011|   3469|   1265|    605|    336|\n",
            "|      0|    1571|  1571|          Ghost Hunt| 7.81|Mystery, Comedy, ...|          Ghost Hunt|                        „Ç¥„Éº„Çπ„Éà„Éè„É≥„Éà|   TV|      25|Oct 4, 2006 to Ma...|  Fall 2006|TV Tokyo, Avex En...|          Funimation|       J.C.Staff| Light novel|25 min. per ep.|PG-13 - Teens 13 ...|   811|       766| 194354.0|     3014|    8115|   107324|   7112|   6964|        64839|   11328|  16683|  24977|  20383|   8600|   4079|   1375|    509|    203|    235|\n",
            "|      0|     578|   578|      Hotaru no Haka| 8.51|   Drama, Historical|Grave of the Fire...|                            ÁÅ´ÂûÇ„Çã„ÅÆÂ¢ì|Movie|       1|        Apr 16, 1988|    Unknown|             Unknown|ADV Films, Centra...|   Studio Ghibli|       Novel|  1 hr. 28 min.|PG-13 - Teens 13 ...|    99|       293| 438214.0|     5407|    5927|   328347|   2713|   1249|        99978|   79553|  69811|  61996|  30066|  11694|   4975|   2350|    953|    539|    845|\n",
            "+-------+--------+------+--------------------+-----+--------------------+--------------------+--------------------------------------+-----+--------+--------------------+-----------+--------------------+--------------------+----------------+------------+---------------+--------------------+------+----------+---------+---------+--------+---------+-------+-------+-------------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import countDistinct, avg\n",
        "\n",
        "users_who_completed_a_series.groupBy(\"user_id\").agg(\n",
        "                              count(\"*\").alias(\"Total_Entries\"),\n",
        "                              countDistinct(\"anime_id\").alias(\"Unique_Anime_Watched\")\n",
        "                          ).show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06tvOQR7q_CX",
        "outputId": "f91132d3-57b2-47b9-b1a3-5f19ce934781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+--------------------+\n",
            "|user_id|Total_Entries|Unique_Anime_Watched|\n",
            "+-------+-------------+--------------------+\n",
            "|    148|           92|                  92|\n",
            "|    496|          156|                 156|\n",
            "|    833|           77|                  77|\n",
            "|   1342|          107|                 107|\n",
            "|   2122|           64|                  64|\n",
            "|   2142|          325|                 325|\n",
            "|   2866|          486|                 486|\n",
            "|   3749|          100|                 100|\n",
            "|   6357|          318|                 318|\n",
            "|   6466|          675|                 675|\n",
            "+-------+-------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animes_df.select([\"MAL_ID\", \"Name\", \"Favorites\"]) \\\n",
        "         .orderBy(col(\"Favorites\").desc()) \\\n",
        "         .show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTaPWzETkuyi",
        "outputId": "97946cbb-a4ed-4591-f692-f30ebbf6f2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------------------------+---------+\n",
            "|MAL_ID|Name                                |Favorites|\n",
            "+------+------------------------------------+---------+\n",
            "|5114  |Fullmetal Alchemist: Brotherhood    |183914   |\n",
            "|9253  |Steins;Gate                         |148452   |\n",
            "|11061 |Hunter x Hunter (2011)              |147274   |\n",
            "|1535  |Death Note                          |145201   |\n",
            "|16498 |Shingeki no Kyojin                  |129844   |\n",
            "|21    |One Piece                           |126645   |\n",
            "|31630 |\"Gyakuten Saiban: Sono \"\"Shinjitsu\"\"|107475   |\n",
            "|1575  |Code Geass: Hangyaku no Lelouch     |90487    |\n",
            "|1735  |Naruto: Shippuuden                  |84651    |\n",
            "|30    |Neon Genesis Evangelion             |71308    |\n",
            "+------+------------------------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL üíª\n",
        "\n",
        "Spark comes with a full SQL engine.\n",
        "\n",
        "<br>\n",
        "\n",
        "We'll recreate this logic using Spark SQL üëáüèæ\n",
        "```\n",
        "from pyspark.sql.functions import col, isnan, when, count\n",
        "\n",
        "anime_df.select([\n",
        "    count(when(isnan(c) | col(c).isNull(), c)).alias(c)\n",
        "    for c in anime_df.columns\n",
        "]).show()\n",
        "```"
      ],
      "metadata": {
        "id": "V6LI3Ub7Lfa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register DataFrame as a temporary view\n",
        "animes_df.createOrReplaceTempView(\"anime\")\n",
        "\n",
        "query = \"\"\"SELECT\n",
        "    SUM(CASE WHEN Rating IS NULL OR isnan(Rating) THEN 1 ELSE 0 END) AS rating,\n",
        "    SUM(CASE WHEN Name IS NULL OR isnan(Name) THEN 1 ELSE 0 END) AS title,\n",
        "    SUM(CASE WHEN MAL_ID IS NULL OR isnan(MAL_ID) THEN 1 ELSE 0 END) AS anime_id,\n",
        "    SUM(CASE WHEN Members IS NULL OR isnan(Members) THEN 1 ELSE 0 END) AS members\n",
        "FROM anime\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIfmkDsMyft8",
        "outputId": "8d8c8d83-b650-4458-f437-788bce7a8ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+--------+-------+\n",
            "|rating|title|anime_id|members|\n",
            "+------+-----+--------+-------+\n",
            "|     0|    0|       0|      0|\n",
            "+------+-----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Catalyst Optimizer\n",
        "\n",
        "This is Spark's engine for writing optimized SQL queries.\n",
        "\n",
        "<br>\n",
        "\n",
        "When you run something like\n",
        "\n",
        "```\n",
        "df.filter(col(\"rating\") > 8).groupBy(\"genre\").avg(\"rating\")\n",
        "```\n",
        "\n",
        "Catalyst steps in and performs four major phases.\n",
        "\n",
        "<br>\n",
        "\n",
        "1. Catalyst builds an unresolved logical plan and turns it into a resolved logical plan once all columns are validated.\n",
        "2. Spark rewrites your query logically to make it faster.\n",
        "3. Spark considers multiple ways to physically run the query\n",
        "  * should it use a sort merge join or a broadcast join?\n",
        "  * should it hash aggregate or sort aggregate?\n",
        "\n",
        "4. Catalyst generates JVM bytecode to execute the plan, so it runs fast.\n",
        "\n",
        "<br>\n",
        "\n",
        "Without Catalyst, you'd have to:\n",
        "- Manually optimize every query\n",
        "- Hand-code joins and filters in the right order\n",
        "- Figure out the best execution strategy based on cluster size and data skew\n",
        "\n",
        "Catalyst saves you from that."
      ],
      "metadata": {
        "id": "JvJP6O9HIWSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öôÔ∏è Optimization Hacks\n",
        "## Caching\n",
        "Spark doesn't automatically cache a dataframe for you. Spark will recompute the entire DAG everytime an action is triggered.\n",
        "\n",
        "Use caching:\n",
        "* When the same DataFrame is used multiple times\n",
        "* After an expensive transformation (e.g., filtering or groupBy)\n",
        "\n",
        "Otherwise, you'll waste time and compute power redoing the same work.\n",
        "\n",
        "## Increasing Partitions\n",
        "More Partitions Can Help When:\n",
        "- You have lots of data and many CPU cores to parallelize work\n",
        "- You're doing CPU-heavy tasks (joins, groupBy, transformations)\n",
        "- You want to avoid skew (e.g., one giant partition that takes forever)\n",
        "\n",
        "Rule of Thumb: You want 2‚Äì4x more partitions than total cores to keep everything busy.\n",
        "\n",
        "If you have more partitions than cores, Spark can:\n",
        "- Keep cores busy all the time, even if some tasks finish earlier than others\n",
        "- Recover faster from slow tasks or stragglers (not all tasks are equal!)\n",
        "- Support better fault tolerance (if a task fails, only that small piece needs to rerun)"
      ],
      "metadata": {
        "id": "6ZPacuwmgQsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚õì Code Patterns\n",
        "\n",
        "### 1. Chain Transformations\n",
        "This allows for cleaner DAGs and easier readability.\n",
        "\n",
        "‚úÖ\n",
        "```\n",
        "df_cleaned = (\n",
        "    df.filter(col(\"rating\").isNotNull())\n",
        "      .withColumn(\"genre\", trim(lower(col(\"genre\"))))\n",
        "      .dropDuplicates([\"id\"])\n",
        ")\n",
        "```\n",
        "‚ùå\n",
        "```\n",
        "df_filtered = df.filter(col(\"rating\").isNotNull())\n",
        "df_lowered = df_filtered.withColumn(\"genre\", lower(col(\"genre\")))\n",
        "df_trimmed = df_lowered.withColumn(\"genre\", trim(col(\"genre\")))\n",
        "df_cleaned = df_trimmed.dropDuplicates([\"id\"])\n",
        "```\n",
        "\n",
        "### 2. Use Built-in Spark Functions\n",
        "Built-ins are faster and Catalyst-optimized.\n",
        "\n",
        "‚úÖ\n",
        "```\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "df = df.withColumn(\"clean_title\", regexp_replace(\"title\", \"[^a-zA-Z0-9 ]\", \"\"))\n",
        "\n",
        "```\n",
        "‚ùå\n",
        "```\n",
        "def remove_special(s):\n",
        "    return re.sub(\"[^a-zA-Z0-9 ]\", \"\", s)\n",
        "\n",
        "remove_special_udf = udf(remove_special)\n",
        "df = df.withColumn(\"clean_title\", remove_special_udf(\"title\"))\n",
        "\n",
        "```\n",
        "\n",
        "### 3. Select Only Columns Needed Early\n",
        "This saves memory and I/O.\n",
        "\n",
        "‚úÖ\n",
        "```\n",
        "df = spark.read.parquet(\"data.parquet\").select(\"id\", \"genre\", \"rating\")\n",
        "\n",
        "```\n",
        "‚ùå\n",
        "```\n",
        "df = spark.read.parquet(\"data.parquet\")  # Loads everything\n",
        "df = df.select(\"id\", \"genre\", \"rating\")  # Unnecessary overhead\n",
        "```\n",
        "\n",
        "### 4. Use Vectorized pandas UDFs\n",
        "Pandas UDFs are vectorized and perform better.\n",
        "\n",
        "‚úÖ\n",
        "```\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "import pandas as pd\n",
        "\n",
        "@pandas_udf(\"double\")\n",
        "def normalize(s: pd.Series) -> pd.Series:\n",
        "    return (s - s.mean()) / s.std()\n",
        "\n",
        "df = df.withColumn(\"rating_norm\", normalize(\"rating\"))\n",
        "```\n",
        "‚ùå\n",
        "```\n",
        "def normalize(x):\n",
        "    return (x - mean) / std\n",
        "\n",
        "norm_udf = udf(normalize)\n",
        "df = df.withColumn(\"rating_norm\", norm_udf(\"rating\"))\n",
        "```\n",
        "\n",
        "### 5. Handling Data Skew with Salting\n",
        "This provides better workload balance and reduces skew.\n",
        "\n",
        "‚úÖ\n",
        "```\n",
        "df_salted = df.withColumn(\"salted_genre\", concat(col(\"genre\"), lit(\"_\"), floor(rand()*10)))\n",
        "df_repartitioned = df_salted.repartition(\"salted_genre\")\n",
        "```\n",
        "‚ùå\n",
        "```\n",
        "df.repartition(\"genre\")  # skew still remains\n",
        "```"
      ],
      "metadata": {
        "id": "RfY0My-kqcAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Back to üêºs\n",
        "\n",
        "There are a few reasons why you'd want to go back to Pandas.\n",
        "\n",
        "- Post-cleaning\n",
        "  - Use Spark to clean or filter down a huge dataset\n",
        "- Conduct analysis on a sample\n",
        "- Visualization\n",
        "  - Spark isn't great for matplotlib, seaborn, or plotly\n",
        "  - Also, many visual tools in Python are looking for a Pandas DataFrame\n",
        "- Modeling using modern ML or Deep Learning libraries\n",
        "  - Spark can be used to prep features\n",
        "  - You'd then switch to Pandas to train a model\n",
        "\n",
        "<br>\n",
        "\n",
        "üí° Best practice: Always filter or sample before converting to pandas"
      ],
      "metadata": {
        "id": "3CtDXbd1u38e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_pandas_df = users_who_completed_a_series.limit(100).toPandas()\n",
        "users_pandas_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "pGl-0QsJwWiy",
        "outputId": "81175425-06e0-49da-def9-3dac9973fd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  anime_id  MAL_ID                                     Name Score  \\\n",
              "0        0        68      68                           Black Cat (TV)  7.38   \n",
              "1        0      1689    1689                    Byousoku 5 Centimeter  7.73   \n",
              "2        0      2913    2913  Daisougen no Chiisana Tenshi: Bush Baby  7.01   \n",
              "3        0      1250    1250                          Erementar Gerad   7.3   \n",
              "4        0       356     356                          Fate/stay night  7.34   \n",
              "\n",
              "                                              Genres  \\\n",
              "0    Sci-Fi, Adventure, Comedy, Super Power, Shounen   \n",
              "1                      Drama, Romance, Slice of Life   \n",
              "2                                   Adventure, Drama   \n",
              "3  Adventure, Comedy, Super Power, Magic, Romance...   \n",
              "4      Action, Supernatural, Magic, Romance, Fantasy   \n",
              "\n",
              "                                  English name       Japanese name   Type  \\\n",
              "0                                    Black Cat            „Éñ„É©„ÉÉ„ÇØ„Ç≠„É£„ÉÉ„Éà     TV   \n",
              "1                     5 Centimeters Per Second          ÁßíÈÄüÔºï„Çª„É≥„ÉÅ„É°„Éº„Éà„É´  Movie   \n",
              "2  Bush Baby, Little Angel of the Great Plains  Â§ßËçâÂéü„ÅÆÂ∞è„Åï„Å™Â§©‰Ωø„ÄÄ„Éñ„ÉÉ„Ç∑„É•„Éô„Ç§„Éì„Éº     TV   \n",
              "3                             Elemental Gelade         „Ç®„É¨„É°„É≥„Çø„É´„Ç∏„Çß„É¨„Ç§„Éâ     TV   \n",
              "4                              Fate/stay night     Fate/stay night     TV   \n",
              "\n",
              "  Episodes  ... Score-10 Score-9 Score-8 Score-7 Score-6 Score-5 Score-4  \\\n",
              "0       23  ...     8654   15253   29392   34019   16081    7534    2521   \n",
              "1        3  ...    65007   80388  107226   86657   43552   21319   10108   \n",
              "2       40  ...       57      54      91     153      93      40      17   \n",
              "3       26  ...     3279    4969    9868   11831    6331    3267    1125   \n",
              "4       24  ...    35378   57284  101538  107818   55337   26103   13081   \n",
              "\n",
              "  Score-3  Score-2  Score-1  \n",
              "0     863      395      234  \n",
              "1    3821     2081     1835  \n",
              "2       4        5        6  \n",
              "3     386      158      103  \n",
              "4    5032     2350     1693  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2975f46c-e58f-470f-a694-afef13ae1f55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>English name</th>\n",
              "      <th>Japanese name</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>...</th>\n",
              "      <th>Score-10</th>\n",
              "      <th>Score-9</th>\n",
              "      <th>Score-8</th>\n",
              "      <th>Score-7</th>\n",
              "      <th>Score-6</th>\n",
              "      <th>Score-5</th>\n",
              "      <th>Score-4</th>\n",
              "      <th>Score-3</th>\n",
              "      <th>Score-2</th>\n",
              "      <th>Score-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>68</td>\n",
              "      <td>Black Cat (TV)</td>\n",
              "      <td>7.38</td>\n",
              "      <td>Sci-Fi, Adventure, Comedy, Super Power, Shounen</td>\n",
              "      <td>Black Cat</td>\n",
              "      <td>„Éñ„É©„ÉÉ„ÇØ„Ç≠„É£„ÉÉ„Éà</td>\n",
              "      <td>TV</td>\n",
              "      <td>23</td>\n",
              "      <td>...</td>\n",
              "      <td>8654</td>\n",
              "      <td>15253</td>\n",
              "      <td>29392</td>\n",
              "      <td>34019</td>\n",
              "      <td>16081</td>\n",
              "      <td>7534</td>\n",
              "      <td>2521</td>\n",
              "      <td>863</td>\n",
              "      <td>395</td>\n",
              "      <td>234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1689</td>\n",
              "      <td>1689</td>\n",
              "      <td>Byousoku 5 Centimeter</td>\n",
              "      <td>7.73</td>\n",
              "      <td>Drama, Romance, Slice of Life</td>\n",
              "      <td>5 Centimeters Per Second</td>\n",
              "      <td>ÁßíÈÄüÔºï„Çª„É≥„ÉÅ„É°„Éº„Éà„É´</td>\n",
              "      <td>Movie</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>65007</td>\n",
              "      <td>80388</td>\n",
              "      <td>107226</td>\n",
              "      <td>86657</td>\n",
              "      <td>43552</td>\n",
              "      <td>21319</td>\n",
              "      <td>10108</td>\n",
              "      <td>3821</td>\n",
              "      <td>2081</td>\n",
              "      <td>1835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2913</td>\n",
              "      <td>2913</td>\n",
              "      <td>Daisougen no Chiisana Tenshi: Bush Baby</td>\n",
              "      <td>7.01</td>\n",
              "      <td>Adventure, Drama</td>\n",
              "      <td>Bush Baby, Little Angel of the Great Plains</td>\n",
              "      <td>Â§ßËçâÂéü„ÅÆÂ∞è„Åï„Å™Â§©‰Ωø„ÄÄ„Éñ„ÉÉ„Ç∑„É•„Éô„Ç§„Éì„Éº</td>\n",
              "      <td>TV</td>\n",
              "      <td>40</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>54</td>\n",
              "      <td>91</td>\n",
              "      <td>153</td>\n",
              "      <td>93</td>\n",
              "      <td>40</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1250</td>\n",
              "      <td>1250</td>\n",
              "      <td>Erementar Gerad</td>\n",
              "      <td>7.3</td>\n",
              "      <td>Adventure, Comedy, Super Power, Magic, Romance...</td>\n",
              "      <td>Elemental Gelade</td>\n",
              "      <td>„Ç®„É¨„É°„É≥„Çø„É´„Ç∏„Çß„É¨„Ç§„Éâ</td>\n",
              "      <td>TV</td>\n",
              "      <td>26</td>\n",
              "      <td>...</td>\n",
              "      <td>3279</td>\n",
              "      <td>4969</td>\n",
              "      <td>9868</td>\n",
              "      <td>11831</td>\n",
              "      <td>6331</td>\n",
              "      <td>3267</td>\n",
              "      <td>1125</td>\n",
              "      <td>386</td>\n",
              "      <td>158</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>356</td>\n",
              "      <td>356</td>\n",
              "      <td>Fate/stay night</td>\n",
              "      <td>7.34</td>\n",
              "      <td>Action, Supernatural, Magic, Romance, Fantasy</td>\n",
              "      <td>Fate/stay night</td>\n",
              "      <td>Fate/stay night</td>\n",
              "      <td>TV</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>35378</td>\n",
              "      <td>57284</td>\n",
              "      <td>101538</td>\n",
              "      <td>107818</td>\n",
              "      <td>55337</td>\n",
              "      <td>26103</td>\n",
              "      <td>13081</td>\n",
              "      <td>5032</td>\n",
              "      <td>2350</td>\n",
              "      <td>1693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2975f46c-e58f-470f-a694-afef13ae1f55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2975f46c-e58f-470f-a694-afef13ae1f55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2975f46c-e58f-470f-a694-afef13ae1f55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-801effde-77bf-42c7-b481-e39a69e3222b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-801effde-77bf-42c7-b481-e39a69e3222b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-801effde-77bf-42c7-b481-e39a69e3222b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "users_pandas_df"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQs ü§î\n",
        "1. Why is Spark slower than pandas on small datasets?\n",
        "> Spark has startup overhead because it launches a JVM, sets up executors, and builds a DAG. For tiny datasets, that overhead outweighs the benefits of distributed computing. Pandas is faster for small data because it's lightweight and runs natively in Python. Spark was built for large datasets.\n",
        "\n",
        "2. What is a partition, and how big is it?\n",
        "> A partition is a chunk of your DataFrame that's processed in parallel by a task on an executor. Spark decides partitioning based on file size, source format, and your config (e.g. spark.sql.shuffle.partitions). You can manually repartition if needed: `df = df.repartition(10)  # Creates 10 partitions`\n",
        "\n",
        "3. How does Spark handle memory? What if my data is too big?\n",
        "> Spark caches data in memory only when you tell it to using `.cache()` or `.persist()`. If memory isn't enough, Spark spills to disk, making it slower but stable. Unlike pandas, Spark won't crash just because your data is too big for RAM.\n",
        "\n",
        "4. What if one executor crashes?\n",
        "> Spark tracks a DAG of all transformations. If a task fails, it recomputes just that partition from upstream steps ‚Äî not the whole dataset.\n"
      ],
      "metadata": {
        "id": "uMxzXbhLj3ec"
      }
    }
  ]
}